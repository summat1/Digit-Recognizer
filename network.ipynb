{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Neural Network From Scratch\n",
    "\n",
    "This project uses basic Python libraries (no TensorFlow, no PyTorch) to implement a neural network. The data is from the MNIST database which contains various \"hand-drawn\" images of digits, sourced from [Kaggle](https://www.kaggle.com/competitions/digit-recognizer). I did this to understand the fundamentals of machine learning and prepare myself for future coding projects. Let's start by importing the libraries and the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Data\n",
    "\n",
    "This dataset has 42000 rows (number of images) and 785 columns. The images are 28 x 28 pixels, for a total of 784 pixels. The additional column is for the label, identifying which digit that image represents. For a given pixel, we have a value from 0 - 255: 255 being completely white, and 0 being completely black. Fortunately, the data comes pre-split into training and testing sets. In the next few code chunks, the data is loaded and prepared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "data = pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A quick peek at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed from a pandas DataFrame to a 2D numpy array and shuffled\n",
    "data = np.array(data)\n",
    "images, inputs = data.shape\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# Transposed so that one column represents one image, with 784 rows per image for pixels\n",
    "data = data.T\n",
    "\n",
    "data_train = data[:, 0:29400]\n",
    "data_test = data[:, 29400:]\n",
    "\n",
    "# Labels split from data \n",
    "# Data normalized to represent pixels between 0 and 1\n",
    "# For both datasets\n",
    "Y_train = data_train[0]\n",
    "X_train = data_train[1:inputs]/255\n",
    "\n",
    "Y_test = data_test[0]\n",
    "X_test = data_test[1:inputs]/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Network Structure\n",
    "\n",
    "We will construct a simple neural network with 3 layers. The input layer has 784 nodes (no parameters). The next layer is the hidden layer and has 10 nodes. The third layer is the output layer that also has 10 nodes. When data passes from one layer to the next, there is a weight and a bias (parameters) applied to transform the input.\n",
    "\n",
    "**Input Layer**:\n",
    "- A0 = X   \n",
    "- Size: (784 x m)\n",
    "\n",
    "**Hidden Layer**:\n",
    "- Z1 = W1 * A0 + b1\n",
    "- Sizes: \n",
    "    - Z1 (10 x m) this is the output of the hidden layer\n",
    "    - W1 (10 x 784) this is the weight applied to the input\n",
    "    - A0 (784 x m) this is the input\n",
    "    - b1 (10 x 1) this is the bias applied\n",
    "\n",
    "*Important Step*: We have to apply an activation function. Because if we did not have one, we would only have an output that is purely a linear combination of the input layer. This cannot give us very meaningful output.\n",
    "\n",
    "We will use a **ReLU** activation function: Rectified Linear Unit. This is a linear function past 0 and a zero function everywhere else.\n",
    "- A1 = g(Z1) = ReLU(Z1)\n",
    "\n",
    "**Output Layer**\n",
    "- Z2 = W2 * A1 + b2\n",
    "- Sizes: \n",
    "    - Z2 (10 x m) this is the output of the output layer\n",
    "    - W2 (10 x 784) this is the weight applied to the activated hidden layer output\n",
    "    - A1 (784 x m) this is the activated output generated from the hidden layer\n",
    "    - b2 (10 x 1) this is the bias applied\n",
    "\n",
    "*Important Step*: We must again apply an activation function that will generate a more useful output from this data. Here we choose softmax, which calculates probabilities of the possible outputs from the raw output layer output data (Z2).\n",
    "\n",
    "- A2 = softmax(Z2)\n",
    "\n",
    "Let's code it up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 784 \n",
    "hidden_layer_size = 10\n",
    "output_layer_size = 10 \n",
    "\n",
    "# Initializing random parameters to start\n",
    "def initialize_params():\n",
    "    W1 = np.random.randn(hidden_layer_size, input_layer_size) * np.sqrt(1 / input_layer_size)\n",
    "    b1 = np.zeros((hidden_layer_size, 1))\n",
    "    W2 = np.random.randn(output_layer_size, hidden_layer_size) * np.sqrt(1 / hidden_layer_size)\n",
    "    b2 = np.zeros((output_layer_size, 1))\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "# We have to define a ReLU function before we can do forward propagation\n",
    "def ReLU(Z):\n",
    "    # This is element-wise, so for each element in Z, it will return either Z or 0 depending on which is larger\n",
    "    return np.maximum(0, Z)\n",
    "\n",
    "# Compute the softmax function\n",
    "def softmax(Z):\n",
    "    return (np.exp(Z)) / (np.sum(np.exp(Z), axis=0))\n",
    "\n",
    "# Now let's apply the formulas and move forward through the network\n",
    "def forward_prop(W1, b1, W2, b2, X):\n",
    "    Z1 = W1.dot(X) + b1\n",
    "    A1 = ReLU(Z1)\n",
    "    \n",
    "    Z2 = W2.dot(A1) + b2\n",
    "    A2 = softmax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "# A cost function to calculate the loss, using cross-entropy here\n",
    "def cross_entropy_loss(Y, Y_hat):\n",
    "    loss = -np.mean(Y * np.log(Y_hat))\n",
    "    return loss\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training our Network\n",
    "\n",
    "Previously, we defined our network. And the formulas we defined above show how we traverse the network in a process known as **forward propagation**. Load in the data, apply weights and biases, and calculate an output. But in order to *train* the model to become better at identifying the digits, we have to check to see if we were right, and specifically, *how right*. This is the principle of **backwards propagation**. As the name suggests, we must essentially apply the inverse of forward propagation. We do this by calculating the error between our output values and the known values (the labels). We apply further formulas to calculate the error in the weights and biases as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Currently Y is in the format of a 1D array of values \n",
    "# For each value, turn it into a vector with a one in the location \n",
    "# of the value and zeros everywhere else\n",
    "def one_hot_encode(Y):\n",
    "    one_hot_Y = np.zeros((Y.size, Y.max() + 1))\n",
    "    one_hot_Y[np.arange(Y.size), Y] = 1\n",
    "    one_hot_Y = one_hot_Y.T\n",
    "    return one_hot_Y\n",
    "\n",
    "# return 1 if Z > 0 (slope of y = x)\n",
    "# return 0 if Z < 0 (slope of y = 0)\n",
    "def der_ReLU(Z):\n",
    "    return Z > 0\n",
    "\n",
    "# Traverse backwards through the network and calculate errors\n",
    "def back_prop(Z1, A1, Z2, A2, W2, X, Y):\n",
    "    m = Y.size\n",
    "    one_hot_Y = one_hot_encode(Y)\n",
    "\n",
    "    # the error in the calculation of Z2 \n",
    "    # (output layer intermediate output)\n",
    "    dZ2 = A2 - one_hot_Y\n",
    "\n",
    "    # the error in the calculation of W2\n",
    "    # (the weight in the output layer)\n",
    "    dW2 = (1/m) * dZ2.dot(A1.T)\n",
    "\n",
    "    # the error in the calculation of b2\n",
    "    # (the bias in the output layer)\n",
    "    db2 = (1/m) * np.sum(dZ2, 1)\n",
    "    db2 = db2.reshape(-1, 1)\n",
    "\n",
    "    # the error in the calculation of Z1\n",
    "    # (the output of the hidden layer)                        \n",
    "    dZ1 = W2.T.dot(dZ2) * der_ReLU(Z1)\n",
    "\n",
    "    # the error in the calculation of W1\n",
    "    # (the weight in the hidden layer)\n",
    "    dW1 = (1/m) * dZ1.dot(X.T)\n",
    "\n",
    "    # the error in the calculation of b1\n",
    "    # (the bias in the hidden layer)\n",
    "    db1 = (1/m) * np.sum(dZ1, 1)\n",
    "    db1 = db1.reshape(-1, 1)\n",
    "\n",
    "    return dW1, db1, dW2, db2  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating our Network\n",
    "\n",
    "From here, we've done most of the hard work. Now, we have to update the weights and biases based on our error calculations. The key part here is defining the learning rate **alpha**, a **hyperparameter**. Alpha defines how strong the updating is. An alpha closer to 1 means that any error highly changes the weights and biases, which can be useful for finding the right parameters but dangerous for causing instability. An alpha closer to 0 means that the values will converge more quickly but not always to the right value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the weights and biases depending on the learning rate, alpha\n",
    "def update(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha):\n",
    "    W1 -= alpha * dW1\n",
    "    b1 -= alpha * db1\n",
    "    W2 -= alpha * dW2\n",
    "    b2 -= alpha * db2\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent\n",
    "\n",
    "Gradient descent is an optimization algorithm - an iterative way to find the optimal weights and biases. This is the crux of the neural network and will use the methods we have previously defined. We start with initial random guesses for the parameters, and feed our training data through the network to calculate our outputs. We then backpropagate the outputs and quantify our error. Finally, we update the weights and biases based on that error. We run for a set number of iterations, and we calculate our accuracy (our output vs the actual labels) to understand how our model is performing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whichever value has the highest probability is the one that we select as the prediction\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "# How accurate we were overall\n",
    "def get_accuracy(predictions, Y):\n",
    "    return np.sum(predictions == Y)/Y.size\n",
    "\n",
    "# Gradient descent\n",
    "def gradient_descent(X, Y, iterations, alpha):\n",
    "    # start with guesses for the weights and biases\n",
    "    W1, b1, W2, b2 = initialize_params()\n",
    "    for i in range(iterations):\n",
    "        # travel forward through the network to calculate output matrices (activated and unactivated)\n",
    "        Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "\n",
    "        # feed those values back through the network and calculate the errors from the correct values that we know (using training data)\n",
    "        dW1, db1, dW2, db2 = back_prop(Z1, A1, Z2, A2, W2, X, Y)\n",
    "\n",
    "        # update the weights and biases based on the error that we calculated \n",
    "        W1, b1, W2, b2 = update(W1, b1, W2, b2, dW1, db1, dW2, db2, alpha)\n",
    "\n",
    "        # print out the results\n",
    "        if i % 25 == 0:\n",
    "            print(\"Iteration # {}\".format(i))\n",
    "            print(\"Accuracy: {:.4f} \".format(get_accuracy(get_predictions(A2), Y)))\n",
    "                            \n",
    "    return W1, b1, W2, b2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running the Model\n",
    "\n",
    "Here is where we employ these techniques and optimize the model, with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration # 0\n",
      "Accuracy: 0.0977 \n",
      "Iteration # 25\n",
      "Accuracy: 0.6216 \n",
      "Iteration # 50\n",
      "Accuracy: 0.7770 \n",
      "Iteration # 75\n",
      "Accuracy: 0.8238 \n",
      "Iteration # 100\n",
      "Accuracy: 0.8471 \n",
      "Iteration # 125\n",
      "Accuracy: 0.8609 \n",
      "Iteration # 150\n",
      "Accuracy: 0.8705 \n",
      "Iteration # 175\n",
      "Accuracy: 0.8780 \n",
      "Iteration # 200\n",
      "Accuracy: 0.8833 \n",
      "Iteration # 225\n",
      "Accuracy: 0.8875 \n",
      "Iteration # 250\n",
      "Accuracy: 0.8910 \n",
      "Iteration # 275\n",
      "Accuracy: 0.8932 \n",
      "Iteration # 300\n",
      "Accuracy: 0.8951 \n",
      "Iteration # 325\n",
      "Accuracy: 0.8968 \n",
      "Iteration # 350\n",
      "Accuracy: 0.8979 \n",
      "Iteration # 375\n",
      "Accuracy: 0.8992 \n",
      "Iteration # 400\n",
      "Accuracy: 0.9013 \n",
      "Iteration # 425\n",
      "Accuracy: 0.9025 \n",
      "Iteration # 450\n",
      "Accuracy: 0.9037 \n",
      "Iteration # 475\n",
      "Accuracy: 0.9048 \n",
      "Iteration # 500\n",
      "Accuracy: 0.9059 \n",
      "Iteration # 525\n",
      "Accuracy: 0.9067 \n",
      "Iteration # 550\n",
      "Accuracy: 0.9079 \n",
      "Iteration # 575\n",
      "Accuracy: 0.9089 \n",
      "Iteration # 600\n",
      "Accuracy: 0.9097 \n",
      "Iteration # 625\n",
      "Accuracy: 0.9103 \n",
      "Iteration # 650\n",
      "Accuracy: 0.9107 \n",
      "Iteration # 675\n",
      "Accuracy: 0.9114 \n",
      "Iteration # 700\n",
      "Accuracy: 0.9119 \n",
      "Iteration # 725\n",
      "Accuracy: 0.9126 \n",
      "Iteration # 750\n",
      "Accuracy: 0.9130 \n",
      "Iteration # 775\n",
      "Accuracy: 0.9134 \n",
      "Iteration # 800\n",
      "Accuracy: 0.9138 \n",
      "Iteration # 825\n",
      "Accuracy: 0.9144 \n",
      "Iteration # 850\n",
      "Accuracy: 0.9153 \n",
      "Iteration # 875\n",
      "Accuracy: 0.9159 \n",
      "Iteration # 900\n",
      "Accuracy: 0.9164 \n",
      "Iteration # 925\n",
      "Accuracy: 0.9168 \n",
      "Iteration # 950\n",
      "Accuracy: 0.9172 \n",
      "Iteration # 975\n",
      "Accuracy: 0.9178 \n",
      "Iteration # 1000\n",
      "Accuracy: 0.9183 \n",
      "Iteration # 1025\n",
      "Accuracy: 0.9187 \n",
      "Iteration # 1050\n",
      "Accuracy: 0.9193 \n",
      "Iteration # 1075\n",
      "Accuracy: 0.9198 \n",
      "Iteration # 1100\n",
      "Accuracy: 0.9202 \n",
      "Iteration # 1125\n",
      "Accuracy: 0.9205 \n",
      "Iteration # 1150\n",
      "Accuracy: 0.9212 \n",
      "Iteration # 1175\n",
      "Accuracy: 0.9214 \n",
      "Iteration # 1200\n",
      "Accuracy: 0.9217 \n",
      "Iteration # 1225\n",
      "Accuracy: 0.9219 \n",
      "Iteration # 1250\n",
      "Accuracy: 0.9222 \n",
      "Iteration # 1275\n",
      "Accuracy: 0.9228 \n",
      "Iteration # 1300\n",
      "Accuracy: 0.9230 \n",
      "Iteration # 1325\n",
      "Accuracy: 0.9233 \n",
      "Iteration # 1350\n",
      "Accuracy: 0.9236 \n",
      "Iteration # 1375\n",
      "Accuracy: 0.9241 \n",
      "Iteration # 1400\n",
      "Accuracy: 0.9242 \n",
      "Iteration # 1425\n",
      "Accuracy: 0.9244 \n",
      "Iteration # 1450\n",
      "Accuracy: 0.9248 \n",
      "Iteration # 1475\n",
      "Accuracy: 0.9251 \n",
      "Iteration # 1500\n",
      "Accuracy: 0.9254 \n",
      "Iteration # 1525\n",
      "Accuracy: 0.9256 \n",
      "Iteration # 1550\n",
      "Accuracy: 0.9256 \n",
      "Iteration # 1575\n",
      "Accuracy: 0.9259 \n",
      "Iteration # 1600\n",
      "Accuracy: 0.9263 \n",
      "Iteration # 1625\n",
      "Accuracy: 0.9265 \n",
      "Iteration # 1650\n",
      "Accuracy: 0.9269 \n",
      "Iteration # 1675\n",
      "Accuracy: 0.9272 \n",
      "Iteration # 1700\n",
      "Accuracy: 0.9276 \n",
      "Iteration # 1725\n",
      "Accuracy: 0.9280 \n",
      "Iteration # 1750\n",
      "Accuracy: 0.9283 \n",
      "Iteration # 1775\n",
      "Accuracy: 0.9287 \n",
      "Iteration # 1800\n",
      "Accuracy: 0.9288 \n",
      "Iteration # 1825\n",
      "Accuracy: 0.9289 \n",
      "Iteration # 1850\n",
      "Accuracy: 0.9293 \n",
      "Iteration # 1875\n",
      "Accuracy: 0.9294 \n",
      "Iteration # 1900\n",
      "Accuracy: 0.9297 \n",
      "Iteration # 1925\n",
      "Accuracy: 0.9299 \n",
      "Iteration # 1950\n",
      "Accuracy: 0.9301 \n",
      "Iteration # 1975\n",
      "Accuracy: 0.9302 \n",
      "Iteration # 2000\n",
      "Accuracy: 0.9303 \n",
      "Iteration # 2025\n",
      "Accuracy: 0.9307 \n",
      "Iteration # 2050\n",
      "Accuracy: 0.9310 \n",
      "Iteration # 2075\n",
      "Accuracy: 0.9311 \n",
      "Iteration # 2100\n",
      "Accuracy: 0.9314 \n",
      "Iteration # 2125\n",
      "Accuracy: 0.9314 \n",
      "Iteration # 2150\n",
      "Accuracy: 0.9317 \n",
      "Iteration # 2175\n",
      "Accuracy: 0.9316 \n",
      "Iteration # 2200\n",
      "Accuracy: 0.9316 \n",
      "Iteration # 2225\n",
      "Accuracy: 0.9317 \n",
      "Iteration # 2250\n",
      "Accuracy: 0.9319 \n",
      "Iteration # 2275\n",
      "Accuracy: 0.9322 \n",
      "Iteration # 2300\n",
      "Accuracy: 0.9323 \n",
      "Iteration # 2325\n",
      "Accuracy: 0.9326 \n",
      "Iteration # 2350\n",
      "Accuracy: 0.9327 \n",
      "Iteration # 2375\n",
      "Accuracy: 0.9328 \n",
      "Iteration # 2400\n",
      "Accuracy: 0.9329 \n",
      "Iteration # 2425\n",
      "Accuracy: 0.9330 \n",
      "Iteration # 2450\n",
      "Accuracy: 0.9332 \n",
      "Iteration # 2475\n",
      "Accuracy: 0.9333 \n"
     ]
    }
   ],
   "source": [
    "# Run the gradient descent with 2500 iterations and a learning rate of 0.1\n",
    "W1, b1, W2, b2 = gradient_descent(X_train, Y_train, 2500, alpha = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing our Model\n",
    "\n",
    "Now we test our model on the testing data. We observe ~93% accuracy, wow! Our model earned an A in classifying digits!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9268 \n"
     ]
    }
   ],
   "source": [
    "# Applying to testing data\n",
    "Z1, A1, Z2, A2 = forward_prop(W1 = W1, b1 = b1, W2 = W2, b2 = b2, X = X_test)\n",
    "preds = get_predictions(A2)\n",
    "print(\"Accuracy: {:.4f} \".format(get_accuracy(preds, Y_test)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Showcasing our Results\n",
    "\n",
    "Let's see it in action! Here, I pull specific images from the training set and compare the model's output with the actual label. It's amazing to see how accurate it is. This has been a great way to explore my interest in machien learning, and I'm excited to start more projects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(X, W1, b1, W2, b2):\n",
    "    Z1, A1, Z2, A2 = forward_prop(W1, b1, W2, b2, X)\n",
    "    predictions = get_predictions(A2)\n",
    "    return predictions\n",
    "\n",
    "def test_prediction(i, W1, b1, W2, b2):\n",
    "    image = X_train[:, i, None]\n",
    "    prediction = make_predictions(image, W1, b1, W2, b2)\n",
    "    label = Y_train[i]\n",
    "\n",
    "    print(\"Our neural network thinks this is a: {}\".format(prediction))\n",
    "    print(\"This is labelled as a: {}\".format(label))\n",
    "\n",
    "    image = image.reshape((28, 28)) * 255\n",
    "    plt.gray()\n",
    "    plt.imshow(image, interpolation=\"nearest\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network thinks this is a: [5]\n",
      "This is labelled as a: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(17, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network thinks this is a: [2]\n",
      "This is labelled as a: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(137, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network thinks this is a: [6]\n",
      "This is labelled as a: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(2314, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network thinks this is a: [0]\n",
      "This is labelled as a: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(7391, W1, b1, W2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our neural network thinks this is a: [9]\n",
      "This is labelled as a: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAMmUlEQVR4nO3dYYhd9ZnH8d/PbPLG5EWy0SEkwXaDgmWRVIew0CIupVUjGAsamxclK7JTpC4t9MWKq9SXsmxbV5FiitJ06VoKaUgE3e1sSAhBKI6aHSdKqxsinTBmNviiFl90TZ59MScyNXP/d3LvOfec5Pl+YLj3nueeex8O+eWce/733L8jQgCufFe13QCA0SDsQBKEHUiCsANJEHYgib8Y5ZvZ5tQ/0LCI8FLLh9qz277D9m9tv2f7kWFeC0CzPOg4u+0Vkn4n6auSZiW9JmlXRLxdWIc9O9CwJvbs2yS9FxEnI+JPkn4haccQrwegQcOEfaOk3y96PFst+zO2J2xP2Z4a4r0ADKnxE3QRsUfSHonDeKBNw+zZT0vavOjxpmoZgA4aJuyvSbre9udtr5L0DUkH62kLQN0GPoyPiE9sPyzpPyWtkPRCRJyorTMAtRp46G2gN+MzO9C4Rr5UA+DyQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IYuD52SXJ9ilJH0k6J+mTiBivoykA9Rsq7JW/jYizNbwOgAZxGA8kMWzYQ9Kvbb9ue2KpJ9iesD1le2rI9wIwBEfE4CvbGyPitO1rJU1K+oeIOFp4/uBvBmBZIsJLLR9qzx4Rp6vbeUn7JW0b5vUANGfgsNu+2vaaC/clfU3STF2NAajXMGfjxyTtt33hdf49Iv6jlq4A1G6oz+yX/GZ8Zgca18hndgCXD8IOJEHYgSQIO5AEYQeSqONCGHTYAw88UKw/++yzxfqJEyeGev2ZGb560RXs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCa56uwxce+21xfrk5GTP2o033lhcd3Z2tlivLmHuaf369cX6xMSSv1YmSXrssceK6z700EPF+tGjPX8UKTWuegOSI+xAEoQdSIKwA0kQdiAJwg4kQdiBJLie/TLw1FNPFes33XRTz9r27duL6x47dmyQlj61a9euYv25557rWVuzZk1x3S1bthTrjLNfGvbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE17N3wPj4eLF++PDhYv2VV17pWes3Dn7u3LlivZ9+19q/+uqrPWv9xtHHxsaK9fn5+WI9q4GvZ7f9gu152zOLlq2zPWn73ep2bZ3NAqjfcg7jfyrpjs8se0TSoYi4XtKh6jGADusb9og4KunDzyzeIWlvdX+vpHvqbQtA3Qb9bvxYRMxV9z+Q1PPDle0JSb1/iAzASAx9IUxEROnEW0TskbRH4gQd0KZBh97O2N4gSdUtp0WBjhs07Acl7a7u75Z0oJ52ADSl72G87Rcl3SZpve1ZSd+X9KSkX9p+UNL7knY22eSV7v777y/W5+bmivXSWHrT4+ilMX6pPJZ+5MiR4rpnz54t1nFp+oY9Inr9S/pKzb0AaBBflwWSIOxAEoQdSIKwA0kQdiAJfkq6A26++eZi/fjx48X6MMNr11xzTbHeb2itX+8l+/btK9bPnz8/8GvjYuzZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmvcLfffnux/swzzxTrGzduLNbffPPNYr00nfT+/fuL66Je7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmmbO6Au+66q1h/6aWXivXSdd9XXVX+/3xqaqpYv/POO4v1p59+uljfubP3r4yvXLmyuC4GM/CUzQCuDIQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7B1gLzks+qm77767WN+0aVPPWr9x9Onp6WK93+/Knzx5slgv/ftinL0ZA4+z237B9rztmUXLnrB92vbx6m97nc0CqN9yDuN/KumOJZb/KCK2Vn8v19sWgLr1DXtEHJX04Qh6AdCgYU7QPWx7ujrMX9vrSbYnbE/ZLn94BNCoQcP+Y0lbJG2VNCfpB72eGBF7ImI8IsYHfC8ANRgo7BFxJiLORcR5ST+RtK3etgDUbaCw296w6OHXJc30ei6Abuj7u/G2X5R0m6T1tmclfV/Sbba3SgpJpyR9q7kWr3z9vutw4MCBEXVysX7Xw69YsaJYP3v2bJ3tYAh9wx4Ru5ZY/HwDvQBoEF+XBZIg7EAShB1IgrADSRB2IAmmbEajXn6Za6S6gj07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBODuKbrjhhmK93+W5jLN3B3t2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCKZtRNDk5Wazfcsstxfq6devqbAfLMPCUzQCuDIQdSIKwA0kQdiAJwg4kQdiBJAg7kATXsyd33XXXFevbtm0r1o8cOVJjN2hS3z277c22D9t+2/YJ29+plq+zPWn73ep2bfPtAhjUcg7jP5H0vYj4gqS/kfRt21+Q9IikQxFxvaRD1WMAHdU37BExFxFvVPc/kvSOpI2SdkjaWz1tr6R7GuoRQA0u6TO77c9J+qKk30gai4i5qvSBpLEe60xImhiiRwA1WPbZeNurJe2T9N2I+MPiWixcTbPkRS4RsScixiNifKhOAQxlWWG3vVILQf95RPyqWnzG9oaqvkHSfDMtAqhD38N425b0vKR3IuKHi0oHJe2W9GR1e6CRDtGoNWvWFOurVq0q1h9//PE620GDlvOZ/UuSvinpLdvHq2WPaiHkv7T9oKT3Je1spEMAtegb9og4JmnJi+ElfaXedgA0ha/LAkkQdiAJwg4kQdiBJAg7kASXuCZ33333Fetnzpwp1qenp+tsBw1izw4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOnty9997bdgsYEfbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AE4+zJrV69ulj/+OOPR9QJmsaeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSWM787Jsl/UzSmKSQtCci/tX2E5L+XtL/Vk99NCJebqpRtGNmZqbtFlCT5Xyp5hNJ34uIN2yvkfS67cmq9qOI+Jfm2gNQl+XMzz4naa66/5HtdyRtbLoxAPW6pM/stj8n6YuSflMtetj2tO0XbK/tsc6E7SnbU8O1CmAYyw677dWS9kn6bkT8QdKPJW2RtFULe/4fLLVeROyJiPGIGB++XQCDWlbYba/UQtB/HhG/kqSIOBMR5yLivKSfSNrWXJsAhtU37LYt6XlJ70TEDxct37DoaV+XxGlboMOWczb+S5K+Kekt28erZY9K2mV7qxaG405J+lYD/aFhe/fuLdZvvfXWEXWCpi3nbPwxSV6ixJg6cBnhG3RAEoQdSIKwA0kQdiAJwg4kQdiBJBwRo3sze3RvBiQVEUsNlbNnB7Ig7EAShB1IgrADSRB2IAnCDiRB2IEkRj1l81lJ7y96vL5a1kVd7a2rfUn0Nqg6e7uuV2GkX6q56M3tqa7+Nl1Xe+tqXxK9DWpUvXEYDyRB2IEk2g77npbfv6SrvXW1L4neBjWS3lr9zA5gdNreswMYEcIOJNFK2G3fYfu3tt+z/UgbPfRi+5Ttt2wfb3t+umoOvXnbM4uWrbM9afvd6nbJOfZa6u0J26erbXfc9vaWetts+7Dtt22fsP2danmr267Q10i228g/s9teIel3kr4qaVbSa5J2RcTbI22kB9unJI1HROtfwLB9q6Q/SvpZRPx1teyfJX0YEU9W/1GujYh/7EhvT0j6Y9vTeFezFW1YPM24pHsk/Z1a3HaFvnZqBNutjT37NknvRcTJiPiTpF9I2tFCH50XEUclffiZxTskXZjGZa8W/rGMXI/eOiEi5iLijer+R5IuTDPe6rYr9DUSbYR9o6TfL3o8q27N9x6Sfm37ddsTbTezhLGImKvufyBprM1mltB3Gu9R+sw0453ZdoNMfz4sTtBd7MsRcbOkOyV9uzpc7aRY+AzWpbHTZU3jPSpLTDP+qTa33aDTnw+rjbCflrR50eNN1bJOiIjT1e28pP3q3lTUZy7MoFvdzrfcz6e6NI33UtOMqwPbrs3pz9sI+2uSrrf9edurJH1D0sEW+riI7aurEyeyfbWkr6l7U1EflLS7ur9b0oEWe/kzXZnGu9c042p527U+/XlEjPxP0nYtnJH/H0n/1EYPPfr6K0n/Xf2daLs3SS9q4bDu/7RwbuNBSX8p6ZCkdyX9l6R1Hert3yS9JWlaC8Ha0FJvX9bCIfq0pOPV3/a2t12hr5FsN74uCyTBCTogCcIOJEHYgSQIO5AEYQeSIOxAEoQdSOL/AQFW8yXq/joSAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_prediction(14713, W1, b1, W2, b2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b79547269aeff725ea9a8cb606707b347017d4b0e3d02348658397a8dd927e95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
